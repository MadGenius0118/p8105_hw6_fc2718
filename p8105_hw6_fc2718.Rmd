---
title: "Homework 6 solutions"
author: "Jeff Goldsmith"
output: github_document
---


```{r, load_libraries, message = FALSE, warning=FALSE}
library(tidyverse)
library(ggridges)
library(modelr)
library(mgcv)
```



## Problem 2
```{r}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2022-01-01",
    date_max = "2022-12-31") |>
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) |>
  select(name, id, everything())
```
### Bootstrap $\hat{r}^2$ value
```{r bootstrap_r_squared}
bootstrap_r_squared = weather_df |> 
  modelr::bootstrap(n=5000) |> 
  mutate (
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data=df)),
    results = map(models,  broom::glance) 
  ) |> 
  select(-strap, -models) |> 
  unnest(results) |> 
  select(r.squared)

```

#### Ploting distribution of $\hat{r}^2$ values
```{r}
ggplot(aes(x = r.squared), data=bootstrap_r_squared) + geom_density()
```
The computed $\hat{r}^2$ is high with an average of `r mean(boostrap_r_squared$r.squared)`, which reflects a significant proportion of the variability in the dependent variable `tmax` can be explained by the independent variables `tmin` and `prcp`. The min of the bootstrap values of $\hat{r}^2$ is `r min(boostrap_r_squared$r.squared)` and the max is `r max(boostrap_r_squared$r.squared)`

#### 95% Confidence Interval of $\hat{r}^2$ values
```{r}
bootstrap_r_squared  |> 
  summarize(
    ci_lower = quantile(r.squared, 0.025), 
    ci_upper = quantile(r.squared, 0.975))
```
#### Bootstrap $\log(\beta_1 * \beta2)$ values
```{r bootstrap beta, warning=FALSE}
bootstrap_beta = weather_df |> 
  modelr::bootstrap(n=5000) |> 
  mutate (
    models = map(strap, \(df) lm(tmax ~ tmin + prcp, data=df)),
    results = map(models,  broom::tidy) 
  ) |> 
  select(-strap, -models) |> 
  unnest(results) |> 
  select(id = `.id`, term, estimate) |> 
  pivot_wider(
    names_from = term,
    values_from =  estimate
  ) |> 
  rename(
    beta1 = tmin,
    beta2 = prcp
  ) |> 
  mutate (
    log_beta1_beta2 = log(beta1 * beta2)
  )
```

#### Plotting distribution of $\log(\beta_1 * \beta2)$ values
```{r plot_beta}
ggplot(aes(x = log_beta1_beta2), data=bootstrap_beta) + geom_density()
```
The distribution of $\log(\beta_1 * \beta2)$ values is highly skewed, with some outliers on the left side.

#### 95% Confidence Interval of $\log(\beta_1 * \beta2)$  values
```{r calc_beta_ci}
bootstrap_beta  |> 
  summarize(
    ci_lower = quantile(log_beta1_beta2, 0.025, na.rm = TRUE), 
    ci_upper = quantile(log_beta1_beta2, 0.975, na.rm = TRUE))
```
## Problem 3
```{r load_clean_data}
birthweight_df =  read_csv("./data/birthweight.csv") |> 
  janitor::clean_names() |> 
  mutate(
    babysex = factor(babysex, labels = c("male", "female")),
    frace = factor(frace, labels = c("white","black","asian", "puerto rican", "other")),
    malform = factor(malform, labels= c("absent", "present")),
    mrace = factor(mrace, labels=c("white", "black", "asian", "puerto rican"))
  ) 
```

```{r examine data}
skimr::skim(birthweight_df)
```
### Construct my model
```{r}
my_model = lm(bwt~., data=birthweight_df) |> 
  step(direction="both")
```

```{r}
summary(my_model)
```
I leveraged stepwise model selection approach to construct the optimal model, where it iteractively adds or removes variables to find the best-fitting model. 

```{r}
birthweight_df |> 
  modelr::add_residuals(my_model) |> 
  modelr::add_predictions(my_model) |> 
  ggplot(aes(x=pred, y=resid)) +
  geom_point(alpha=0.5) +
  labs( 
    x= "Fitted Values", 
    y = "Residuals",
    title = "Residuals against Fitted values") 
```
### Compare with other two models 
```{r}
cv_df = 
  crossv_mc(birthweight_df, 100) |> 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble)
    ) |> 
  mutate(
    model_1 = map(train, \(df) lm(bwt ~blength + gaweeks, data=df)),
    model_2 = map(train, \(df) lm(bwt ~bhead + blength + babysex + bhead*blength + 
                                    bhead*babysex + blength*babysex + 
                                    bhead*blength*babysex, data=df)),
    my_model = map(train, \(df) lm(bwt ~ babysex + bhead + blength + delwt + fincome + 
                                     gaweeks + mheight + mrace + parity + ppwt + 
                                     smoken,data=df))
    ) |> 
  mutate(
    rmse_model_1 =map2_dbl(model_1, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_model_2 =map2_dbl(model_2, test, \(mod, df) rmse(model = mod, data = df)),
    rmse_my_model =map2_dbl(my_model, test, \(mod, df) rmse(model = mod, data = df))
  )

  
```


```{r}
cv_df |> 
  select(starts_with("rmse")) |> 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") |> 
  mutate(model = fct_inorder(model)) |> 
  ggplot(aes(x = model, y = rmse)) + geom_violin() +
  labs(
    y= "rmse", 
    x = "Models",
    title = "Comparison of three models")

```
As perceived from the graph, `my_model` has the lowest rmse value overall, where lower the rmse score, the closer to the actual values.  `model_1` has the largest rmse value. To conclude, `my_model` performed the best among the three proposed models.